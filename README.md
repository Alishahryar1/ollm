# localLLM
 
| Model   | Weights | KV cache | Hidden states | Emb+Head | **Total**    | 
| ------- | ------- | -------- | ------------- | -------- | ------------ |
| **1B**  | 2 GB    | 12.6 GB  | 0.4 GB        | 1.0 GB   | **\~16 GB**  |
| **8B**  | 16 GB   | 52.4 GB  | 0.8 GB        | 2.0 GB   | **\~71 GB**  |
| **70B** | 140 GB  | 262 GB   | 1.6 GB        | 4.0 GB   | **\~408 GB** |


## llama3-8B
- on simple test (30 tokens generation with simple output):

